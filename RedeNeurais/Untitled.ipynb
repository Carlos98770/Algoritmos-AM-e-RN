{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0460ee43-9d80-4b81-982e-96c3db9afdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "255f5e3d-85e7-41cf-80f8-5cea8ad1c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,Y = load_iris(return_X_y=True,as_frame = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3308e814-a200-480d-940e-eafe0c96d149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = np.ones(len(x))*-1\n",
    "\n",
    "x0_colum = pd.DataFrame(x0)\n",
    "\n",
    "X = pd.concat([x0_colum,x],axis=1,ignore_index=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=32)\n",
    "\n",
    "len(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be11610-98fd-43b6-a0ee-d520f3039482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/car/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Suponha que y_train contenha os rótulos 0, 1 e 2\n",
    "y_train = Y_train.to_numpy() # Exemplo de dados\n",
    "\n",
    "# Reshape para uma matriz de uma coluna, pois o OneHotEncoder espera um array 2D\n",
    "y_train_reshaped = y_train.reshape(-1, 1)\n",
    "\n",
    "# Criar uma instância do OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "# Ajustar e transformar os rótulos\n",
    "y_train_one_hot = encoder.fit_transform(y_train_reshaped)\n",
    "\n",
    "print(len(y_train_one_hot))\n",
    "print(y_train_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7b1522-1979-46bd-92fa-3031248abd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/car/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Suponha que y_train contenha os rótulos 0, 1 e 2\n",
    "y_test = Y_test.to_numpy() # Exemplo de dados\n",
    "\n",
    "# Reshape para uma matriz de uma coluna, pois o OneHotEncoder espera um array 2D\n",
    "y_test_reshaped = y_test.reshape(-1, 1)\n",
    "\n",
    "# Criar uma instância do OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "# Ajustar e transformar os rótulos\n",
    "y_test_one_hot = encoder.fit_transform(y_test_reshaped)\n",
    "\n",
    "print(len(y_test_one_hot))\n",
    "print(y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "30503761-6784-4b21-a2c1-cbc85d348942",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "w1 = np.random.uniform(low=-1, high=1, size=(3, 5))\n",
    "w2 = np.random.uniform(low=-1, high=1, size=(2, 4))\n",
    "w3 = np.random.uniform(low=-1, high=1, size=(3, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e2a9f493-b8d3-4f1c-af70-4c3ba101a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0.2\n",
    "e = 1e-8\n",
    "epoca = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "27a26fd4-84f0-45d4-b687-4a46ed1cc016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(u):\n",
    "    return np.maximum(0, u)\n",
    "  \n",
    "\n",
    "def g_dev(u):\n",
    "  if u > 0:\n",
    "    return 1\n",
    "\n",
    "  else:\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7a40cdf0-1b51-44d9-8b42-ec805889a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "def softmax_derivative(x):\n",
    "    s = softmax(x)\n",
    "    return s * (1 - s)  # A derivada da função softmax é softmax * (1 - softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ac8ff908-82e0-44da-8991-5fa39d41dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erm(d,y):\n",
    "  erro = 0\n",
    "  for i in range(len(d)):\n",
    "    for j in range(len(d[i])):\n",
    "      erro += ((d[i][j] - y[j])**2)/2\n",
    "    \n",
    "  \n",
    "  return erro/len(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a520d5e9-289c-4ee4-b629-6ce60a76e3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07945598263058251, 5.4524987734286725, 4.560642969884382]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_1 = []\n",
    "for j in range(len(w1)):\n",
    "  z = np.dot(X_train.iloc[0,:],w1[j].T)\n",
    "  i_1.append(z)\n",
    "\n",
    "i_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ac8c8365-0fa7-4188-8d7b-64f71a3b7e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.        ,  0.07945598,  5.45249877,  4.56064297])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1 = g(i_1)\n",
    "\n",
    "y_1 = np.insert(y_1,0,-1)\n",
    "\n",
    "y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "755074bd-75e4-4415-b480-566cec26109c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.252086369431773, -7.832311933980734]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_2 = []\n",
    "for j in range(len(w2)):\n",
    "  m = np.dot(y_1,w2[j].T)\n",
    "  i_2.append(m)\n",
    "\n",
    "i_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7b398a27-f628-48e8-b3f0-87dd62133107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.        ,  2.25208637,  0.        ])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2 = g(i_2)\n",
    "\n",
    "y_2 = np.insert(y_2,0,-1)\n",
    "\n",
    "y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c068b041-eaaa-49e6-9c6b-38aea434dc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.08880015233550043, 1.4816170724517705, 0.44639413359966384]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_3 = []\n",
    "for j in range(len(w3)):\n",
    "  k = np.dot(y_2, w3[j].T)\n",
    "  i_3.append(k)\n",
    "\n",
    "i_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae48e089-a031-4e18-8741-08064316389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.20987035, 0.        , 0.3471906 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_3 = g(i_3)\n",
    "\n",
    "y_3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b497dffc-dc24-406e-a4a9-7ca207e99678",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  errom = erm(y_train_one_hot,y_3)\n",
    "  for w in range(1,len(X_train) - 1 ):\n",
    "    ##Passo Forward\n",
    "    i_1 = []\n",
    "    for j in range(len(w1)):\n",
    "      z = np.dot(X_train.iloc[w,:],w1[j])\n",
    "      i_1.append(z)\n",
    "\n",
    "    y_1 = g(i_1)\n",
    "    y_1 = np.insert(y_1,0,-1)\n",
    "\n",
    "    i_2 = []\n",
    "    for j in range(len(w2)):\n",
    "      m = np.dot(y_1,w2[j].T)\n",
    "      i_2.append(m)\n",
    "\n",
    "    y_2 = g(i_2)\n",
    "    y_2 = np.insert(y_2,0,-1)\n",
    "\n",
    "    i_3 = []\n",
    "    for j in range(len(w3)):\n",
    "      k = np.dot(y_2,w3[j].T)\n",
    "      i_3.append(k)\n",
    "\n",
    "    y_3 = g(i_3)\n",
    "    ##Passo backward\n",
    "    delta_3 = []\n",
    "\n",
    "    for i in range(len(w3)):\n",
    "      delta = (y_train_one_hot[w,i] - y_3[i]) * g_dev(i_3[i])\n",
    "\n",
    "      delta_3.append(delta)\n",
    "\n",
    "      \n",
    "    for j in range(len(w3)):\n",
    "      for i in range(len(w3[j])):\n",
    "        w3[j][i] = w3[j][i] + n*(delta_3[j] * y_2[j])\n",
    "\n",
    "\n",
    "\n",
    "    ####\n",
    "    delta_2 = []\n",
    "\n",
    "    for i in range(len(w2)):\n",
    "      z = 0\n",
    "      for k in range(len(w3)):\n",
    "        z += np.dot(delta_3,w3[k])\n",
    "\n",
    "\n",
    "      delta_2.append(z * g_dev(i_2[i]))\n",
    "\n",
    "\n",
    "\n",
    "    for j in range(len(w2)):\n",
    "      for i in range(len(w2[j])):\n",
    "        w2[j][i] = w2[j][i] + n*(delta_2[j] * y_1[j])\n",
    "\n",
    "\n",
    "    ######\n",
    "    delta_1 = []\n",
    "\n",
    "    for i in range(len(w1)):\n",
    "      z = 0\n",
    "      for k in range(len(w2)):\n",
    "        z+= np.dot(delta_2,w2.T[k])\n",
    "\n",
    "      delta_1.append(z * g_dev(i_1[i]))\n",
    "\n",
    "\n",
    "    for j in range(len(w1)):\n",
    "      for i in range(len(w1[j])):\n",
    "        w1[j][i] = w1[j][i] + n*(delta_1[j] * X_train.iloc[w,i])\n",
    "\n",
    "\n",
    "  em_atual = erm(y_train_one_hot,y_3)\n",
    "  epoca +=1\n",
    "  if abs(em_atual-errom) < e:\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2b518461-4e82-4574-aeef-d5d81635d776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13304181, 0.63975204, 0.22720614])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_3 = softmax(i_3)\n",
    "\n",
    "y_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b362bf8a-6d71-4d4e-94a0-70fd767f1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = pd.DataFrame(normalization(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86cf2924-ce5e-4b33-96a6-88083f7c3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c639c9-1466-4913-bd22-6f0d0ef8e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47d9ac-4ef6-4a42-85ee-d3486db8c337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
